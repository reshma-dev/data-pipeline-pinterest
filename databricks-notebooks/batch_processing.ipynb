{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f300c42b-17a8-4013-ae5c-fb409a7c76a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Read AWS keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7442ca5b-0f7a-4008-be12-e79539378193",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./get_aws_keys\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b5cb1a2-fbe1-45b2-9721-ca5ad3a1a91f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Mount S3 bucket to Databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f1ac9ee-7214-4e58-9cdd-4469dd48a54a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def is_S3_mounted(mount_name:str):\n",
    "    for mount in dbutils.fs.ls(\"/mnt\"):\n",
    "        if mount_name in mount.name:\n",
    "            print(f\"{mount.name} : {mount.path}\")\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Mount name for the bucket\n",
    "MOUNT_NAME = \"pinterest_data_s3_12e37\"\n",
    "\n",
    "if not is_S3_mounted(mount_name=MOUNT_NAME):\n",
    "    \n",
    "    # AWS S3 bucket name\n",
    "    AWS_S3_BUCKET = \"user-12e371d757c1-bucket\"\n",
    "\n",
    "    # Source url\n",
    "    SOURCE_URL = \"s3a://{0}:{1}@{2}\".format(ACCESS_KEY, ENCODED_SECRET_KEY, AWS_S3_BUCKET)\n",
    "\n",
    "    # Mount the drive\n",
    "    dbutils.fs.mount(SOURCE_URL, \"/mnt/\" + MOUNT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e13bb90-1155-4660-aa4a-0555d192708a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Read data for the pin, geo and user topics from the mounted S3 into corresponding 3 DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfa58cf5-0084-4c18-b559-14bac18f967c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample file_location = \"/mnt/pinterest_data_s3_12e37/topics/12e371d757c1.geo/partition=0/*.json\" \n",
    "\n",
    "def read_data(path):\n",
    "    \"\"\" Read all .json files from the mounted S3 bucket\n",
    "    \"\"\"\n",
    "    file_type = \"json\"\n",
    "    infer_schema = \"true\"\n",
    "    \n",
    "    # Read in JSONs from mounted S3 bucket\n",
    "    df = spark.read.format(file_type) \\\n",
    "    .option(\"inferSchema\", infer_schema) \\\n",
    "    .load(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "path_to_topics = \"/mnt/pinterest_data_s3_12e37/topics/\"\n",
    "aws_iam_username = \"12e371d757c1\"\n",
    "\n",
    "# Create DataFrames for the three topics:\n",
    "\n",
    "# df_pin for the Pinterest post data\n",
    "df_pin = read_data(path_to_topics + aws_iam_username + \".\" + \"pin\" + \"/partition=0/*.json\")\n",
    "\n",
    "# df_geo for the geolocation data\n",
    "df_geo = read_data(path_to_topics + aws_iam_username + \".\" + \"geo\" + \"/partition=0/*.json\")\n",
    "\n",
    "# df_user for the user data\n",
    "df_user = read_data(path_to_topics + aws_iam_username + \".\" + \"user\" + \"/partition=0/*.json\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cb5f539-0e77-43ef-9f97-9db48253bcf2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Data Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b3ea4d9-63ae-4497-982b-6f1ea8fc9a0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./data_cleaning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "758a6293-f726-4bcd-aa0c-5b7280a238cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cleaned_df_pin = clean_df_pin(df_pin)\n",
    "cleaned_df_geo = clean_df_geo(df_geo)\n",
    "cleaned_df_user = clean_df_user(df_user)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "batch_processing",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
