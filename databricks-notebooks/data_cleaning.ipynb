{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec34aafb-891a-4e60-87eb-edc80556d429",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Data Cleaning functions for pin, user and geo DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1190330-1e90-48f8-be99-e5574568929e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean the `df_pin` DataFrame\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "def clean_df_pin(df_pin):\n",
    "    \"\"\"Clean the DataFrame that contains information about Pinterest posts\n",
    "    \"\"\"\n",
    "    # Drop duplicate rows with matching index values\n",
    "    cleaned_df_pin = df_pin.dropDuplicates(['index'])\n",
    "    \n",
    "    # 1. Replace empty entries and entries with no relevant data in each column with Nones\n",
    "    cleaned_df_pin = cleaned_df_pin.replace({'User Info Error': None}, subset=['follower_count', 'poster_name'])\n",
    "    cleaned_df_pin = cleaned_df_pin.replace({'Image src error.': None}, subset=['image_src'])\n",
    "    cleaned_df_pin = cleaned_df_pin.replace({'N,o, ,T,a,g,s, ,A,v,a,i,l,a,b,l,e': None}, subset=['tag_list'])\n",
    "    cleaned_df_pin = cleaned_df_pin.replace({'No description available': None, 'No description available Story format': None}, subset=['description'])\n",
    "    cleaned_df_pin = cleaned_df_pin.replace({'No Title Data Available': None}, subset=['title'])\n",
    "    \n",
    "    # 2. Convert the 'follower_count' values listed in 'k' or 'M' to the corresponding numeric values\n",
    "    cleaned_df_pin = cleaned_df_pin.withColumn(\"follower_count\", regexp_replace(\"follower_count\", \"k\", \"000\"))\n",
    "    cleaned_df_pin = cleaned_df_pin.withColumn(\"follower_count\", regexp_replace(\"follower_count\", \"M\", \"000000\"))\n",
    "\n",
    "    # 3. Ensure that each column containing numeric data has a numeric data type\n",
    "\n",
    "    # Change data type of follower_count column to int\n",
    "    cleaned_df_pin = cleaned_df_pin.withColumn(\"follower_count\", cleaned_df_pin[\"follower_count\"].cast(\"int\"))\n",
    "    \n",
    "    # 4. Clean the data in the save_location column to include only the save location path\n",
    "    cleaned_df_pin = cleaned_df_pin.withColumn(\"save_location\", regexp_replace(\"save_location\", \"Local save in \", \"\"))\n",
    "    \n",
    "    # 5.  Rename the index column to 'ind'\n",
    "    cleaned_df_pin = cleaned_df_pin.withColumnRenamed(\"index\", \"ind\")\n",
    "    \n",
    "    # 6. Reorder the DataFrame columns\n",
    "    cleaned_df_pin = cleaned_df_pin.select(\"ind\", \"unique_id\", \"title\", \"description\", \"follower_count\", \"poster_name\", \"tag_list\", \"is_image_or_video\", \"image_src\", \"save_location\", \"category\", \"downloaded\")\n",
    "    \n",
    "    return cleaned_df_pin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a33e5a78-4525-4a8e-8c8b-766346dc7f22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean the `df_geo` DataFrame\n",
    "\n",
    "def clean_df_geo(df_geo):\n",
    "    \"\"\"Clean the DataFrame that contains information about geolocation of the posts\n",
    "    \"\"\"\n",
    "    # Drop duplicate rows with matching ind values\n",
    "    cleaned_df_geo = df_geo.dropDuplicates(['ind'])\n",
    "    \n",
    "    # 1. Create a new column coordinates that contains an array based on the latitude and longitude columns\n",
    "    cleaned_df_geo = cleaned_df_geo.withColumn(\"coordinates\", array(\"latitude\", \"longitude\"))\n",
    "\n",
    "    # 2. Drop the latitude and longitude columns from the DataFrame\n",
    "    cleaned_df_geo = cleaned_df_geo.drop(\"latitude\", \"longitude\")\n",
    "\n",
    "    # 3. Convert the timestamp column from a string to a timestamp data type\n",
    "    cleaned_df_geo = cleaned_df_geo.withColumn(\"timestamp\", to_timestamp(\"timestamp\"))\n",
    "\n",
    "    # 4. Reorder the DataFrame columns to have the following column order:\n",
    "    cleaned_df_geo = cleaned_df_geo.select(\"ind\", \"country\", \"coordinates\", \"timestamp\")\n",
    "    \n",
    "    return cleaned_df_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a9f206f-eb5c-4fb2-8584-b6de57536e08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean the `df_user` DataFrame\n",
    "\n",
    "def clean_df_user(df_user):\n",
    "    \"\"\"Clean the DataFrame that contains information about users\n",
    "    \"\"\"\n",
    "    # Drop duplicate rows with matching ind values\n",
    "    cleaned_df_user = df_user.dropDuplicates(['ind'])\n",
    "    \n",
    "    # 1. Create a new column user_name that concatenates the information found in the first_name and last_name columns\n",
    "    cleaned_df_user = cleaned_df_user.withColumn(\"user_name\", concat(\"first_name\", lit(\" \"), \"last_name\"))\n",
    "\n",
    "    # 2. Drop the first_name and last_name columns from the DataFrame\n",
    "    cleaned_df_user = cleaned_df_user.drop(\"first_name\", \"last_name\")\n",
    "\n",
    "    # 3. Convert the date_joined column from a string to a timestamp data type\n",
    "    cleaned_df_user = cleaned_df_user.withColumn(\"date_joined\", to_timestamp(\"date_joined\"))\n",
    "\n",
    "    # 4. Reorder the DataFrame columns\n",
    "    cleaned_df_user = cleaned_df_user.select(\"ind\", \"user_name\", \"age\", \"date_joined\")\n",
    "    \n",
    "    return cleaned_df_user"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "data_cleaning",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
